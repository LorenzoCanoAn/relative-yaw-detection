{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tunnel_yaw_prediction.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "importlib.reload(models)\n",
    "cuda = torch.device('cuda')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_NAME = \"fast_tunnel_traversal\"\n",
    "DATA_FOLDER_PATH = f\"/home/lorenzo/datasets/{DATA_FOLDER_NAME}\"\n",
    "MODEL = models.TunnelYawPredictor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check datasets available in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 2023-06-30_11:27:44  n_envs: 20 info: {'max_inclination_deg': 10, 'name': '2023-06-30_11:27:44', 'number_of_samples_per_env': 10000, 'label_range_deg': 45, 'max_horizontal_displacement': 2, 'max_coord_val': 15, 'img_size': 30}\n"
     ]
    }
   ],
   "source": [
    "datasets_data = {}\n",
    "for env_folder in os.listdir(DATA_FOLDER_PATH):\n",
    "    env_folder_path = os.path.join(DATA_FOLDER_PATH, env_folder)\n",
    "    env_data_folder_path = os.path.join(env_folder_path, \"data\")\n",
    "    for dataset_name in os.listdir(env_data_folder_path):\n",
    "        if dataset_name in datasets_data.keys():\n",
    "            datasets_data[dataset_name][\"env\"].append(env_folder)\n",
    "            datasets_data[dataset_name][\"n_envs\"] += 1\n",
    "        else:\n",
    "            dataset_info_file_path = os.path.join(env_data_folder_path, dataset_name, \"info.json\")\n",
    "            with open(dataset_info_file_path, \"r\") as f:\n",
    "                dataset_info = json.load(f)\n",
    "            datasets_data[dataset_name] = {\"info\":dataset_info, \"env\":[env_folder,], \"n_envs\":1}\n",
    "for dataset in datasets_data:\n",
    "    dataset_data = datasets_data[dataset]\n",
    "    n_envs = dataset_data[\"n_envs\"]\n",
    "    info = dataset_data[\"info\"]\n",
    "    print(f\"dataset: {dataset}  n_envs: {n_envs} info: {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"2023-06-30_11:27:44\"\n",
    "SAVE_FOLDER = f\"/home/lorenzo/models/yaw_estimation/{DATA_FOLDER_NAME}/{DATASET}\"\n",
    "n_epochs = int(64*2)\n",
    "batch_size = 128\n",
    "lr = 0.002\n",
    "try:\n",
    "    os.makedirs(SAVE_FOLDER)\n",
    "except:\n",
    "    pass\n",
    "save_path = os.path.join(SAVE_FOLDER,MODEL.__name__+f\"-_bs{batch_size}_ne{n_epochs}_lr{str(lr).replace('.','_')}.torch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env_001\n",
      "env_002\n",
      "env_003\n",
      "env_004\n",
      "env_005\n",
      "env_006\n",
      "env_007\n",
      "env_008\n",
      "env_009\n",
      "env_010\n",
      "env_011\n",
      "env_012\n",
      "env_013\n",
      "env_014\n",
      "env_015\n",
      "env_016\n",
      "env_017\n",
      "env_018\n",
      "env_019\n",
      "env_020\n",
      "9999\r"
     ]
    }
   ],
   "source": [
    "# Define the dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path_to_data_folder,dataset_name, max_elements_per_env=None):\n",
    "        self.device = torch.device(\n",
    "            \"cuda:0\")\n",
    "        self.load_dataset(path_to_data_folder, dataset_name, max_elements_per_env=max_elements_per_env)\n",
    "        self.data_augmentation=torch.nn.Sequential(\n",
    "            transforms.RandomErasing()\n",
    "        )\n",
    "    def load_dataset(self, path_to_data_folder, dataset_name, max_elements_per_env = None):\n",
    "        n_datapoints = 0\n",
    "        envs = os.listdir(path_to_data_folder)\n",
    "        envs.sort()\n",
    "        for env in envs:\n",
    "            env_folder = os.path.join(path_to_data_folder, env)\n",
    "            path_to_dataset = os.path.join(env_folder, \"data\", dataset_name)\n",
    "            if os.path.isdir(path_to_dataset):\n",
    "                if max_elements_per_env is None:\n",
    "                    n_datapoints += len(os.listdir(path_to_dataset))-1\n",
    "                else:\n",
    "                    n_datapoints+=min(len(os.listdir(path_to_dataset))-1,max_elements_per_env)\n",
    "            else:\n",
    "                envs.remove(env)\n",
    "        self.n_datapoints = n_datapoints\n",
    "        self.labels = torch.zeros((self.n_datapoints, 1)).float()\n",
    "        self.images = torch.zeros((self.n_datapoints,1,30,30)).float()\n",
    "        n = 0\n",
    "        for env in envs:\n",
    "            print(env)\n",
    "            env_folder = os.path.join(path_to_data_folder, env)\n",
    "            path_to_dataset = os.path.join(env_folder, \"data\", dataset_name)\n",
    "            dtp_names = os.listdir(path_to_dataset)\n",
    "            dtp_names.sort()\n",
    "            # Remove the info.json\n",
    "            dtp_names.pop(-1)\n",
    "            if not max_elements_per_env is None:\n",
    "                dtp_names = dtp_names[0:min(len(dtp_names),max_elements_per_env)]\n",
    "            for dtp_n, dtp_name in enumerate(dtp_names):\n",
    "                print(f\"{dtp_n:04d}\",end=\"\\r\")\n",
    "                dtp_path = os.path.join(path_to_dataset, dtp_name)\n",
    "                dtp = np.load(dtp_path)\n",
    "                self.labels[n, :] = torch.tensor(dtp[\"label\"])\n",
    "                self.images[n,0, :,:] = torch.tensor(dtp[\"image\"])\n",
    "                n+=1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_datapoints\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx, ...]\n",
    "        result = self.labels[idx, ...]\n",
    "        return image.float(), result.float()\n",
    "    def delete(self, idx):\n",
    "        self.images = torch.cat(self.images[0:idx,...],self.images[idx+1,:])\n",
    "        self.labels= torch.cat(self.labels[0:idx,...],self.labels[idx+1,:])\n",
    "\n",
    "env_folder = ImageDataset(DATA_FOLDER_PATH,DATASET,max_elements_per_env=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-29.3962])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, result = env_folder[n]\n",
    "n+=1\n",
    "print(np.rad2deg(result))\n",
    "plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(env_folder,[0.9,0.1])\n",
    "torch.cuda.empty_cache()\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=5)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=5)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_train(network, train_loader, criterion, optimizer, n_epochs,lr,tensorborad_folder=\"/home/lorenzo/tensor_board\"):\n",
    "    shutil.rmtree(tensorborad_folder) \n",
    "    os.mkdir(tensorborad_folder)\n",
    "    writer = SummaryWriter(log_dir=tensorborad_folder)\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        print(\"\", end=\"\\r\")\n",
    "        print(\"Epoch {} out of {}\".format(\n",
    "            epoch + 1, n_epochs), end=\"\")\n",
    "        for i, data in enumerate(train_loader):\n",
    "            torch.cuda.empty_cache()\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(torch.device(\"cuda\"))\n",
    "            labels = labels.to(torch.device(\"cuda\"))\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            j = i + epoch * train_loader.__len__()\n",
    "            writer.add_scalar(f\"Loss/train/lr_{lr}\",loss,j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(\"/home/lorenzo/models/gallery_detection/procedural_datasets/dataset_03/gallery_detector_v3-_r10_lr002_3.torch\", \"rb\") as f:\n",
    "        network.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100000\n",
      "0.065000\n",
      "0.042250\n",
      "0.027463\n",
      "0.017851\n",
      "0.011603\n",
      "0.007542\n",
      "0.004902\n",
      "0.003186\n",
      "0.002071\n",
      "0.001346\n",
      "0.000875\n",
      "0.000569\n",
      "0.000370\n",
      "0.000240\n",
      "0.000156\n",
      "0.000102\n",
      "0.000066\n",
      "0.000043\n",
      "0.000028\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.1*0.65**n for n in range(20)]\n",
    "for i in lrs:\n",
    "    print(f\"{i:05f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 128"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 out of 128"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "network = MODEL().to(cuda).float()\n",
    "torch.cuda.empty_cache()\n",
    "optimizer = torch.optim.Adam(\n",
    "    network.parameters(),\n",
    "    lr=lr,\n",
    ")\n",
    "loss_hist = basic_train(\n",
    "    network, train_dataloader, criterion, optimizer, n_epochs, lr\n",
    ")\n",
    "lr_str = f\"{lr:04f}\".replace(\".\", \"_\")\n",
    "network.to(\"cpu\")\n",
    "torch.save(network.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/models/gallery_detection/procedural_datasets/dataset_03/gallery_detector_v3-_r10_lr002_5.torch\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/lorenzo/models/gallery_detection/procedural_datasets/dataset_03/gallery_detector_v3-_r10_lr002_5.torch\"\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
