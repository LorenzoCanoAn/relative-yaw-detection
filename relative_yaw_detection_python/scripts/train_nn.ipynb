{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaw_estimation.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "importlib.reload(models)\n",
    "cuda = torch.device('cuda')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/models/gallery_detection/procedural_datasets/fast_tunnel_traversal/YawEstimator-_bs128_ne1_lr0_002.torch\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"fast_tunnel_traversal\"\n",
    "DATASET_FOLDER = f\"/home/lorenzo/datasets/{DATASET}\"\n",
    "MODEL = models.YawEstimator\n",
    "SAVE_FOLDER = f\"/home/lorenzo/models/gallery_detection/procedural_datasets/{DATASET}\"\n",
    "n_epochs = int(64*2)\n",
    "n_epochs = 1\n",
    "batch_size = 128\n",
    "lr = 0.002\n",
    "try:\n",
    "    os.mkdir(SAVE_FOLDER)\n",
    "except:\n",
    "    pass\n",
    "save_path = os.path.join(SAVE_FOLDER,MODEL.__name__+f\"-_bs{batch_size}_ne{n_epochs}_lr{str(lr).replace('.','_')}.torch\")\n",
    "print(save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env_001\n",
      "env_002\n",
      "env_003\n",
      "env_004\n",
      "env_005\n",
      "env_006\n",
      "env_007\n",
      "env_008\n",
      "env_009\n",
      "env_010\n",
      "env_011\n",
      "env_012\n",
      "env_013\n",
      "env_014\n",
      "env_015\n",
      "env_016\n",
      "env_017\n",
      "env_018\n",
      "env_019\n",
      "env_020\n",
      "9999\r"
     ]
    }
   ],
   "source": [
    "# Define the dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path_to_dataset, max_elements_per_env=None):\n",
    "        self.device = torch.device(\n",
    "            \"cuda:0\")\n",
    "        self.load_dataset(path_to_dataset,max_elements_per_env=max_elements_per_env)\n",
    "        self.data_augmentation=torch.nn.Sequential(\n",
    "            transforms.RandomErasing()\n",
    "        )\n",
    "    def load_dataset(self, dataset_folder, max_elements_per_env = None):\n",
    "        n_datapoints = 0\n",
    "        envs = os.listdir(dataset_folder)\n",
    "        envs.sort()\n",
    "        for env in envs:\n",
    "            env_folder = os.path.join(dataset_folder, env)\n",
    "            data_folder = os.path.join(env_folder, \"data\")\n",
    "            if os.path.isdir(data_folder):\n",
    "                if max_elements_per_env is None:\n",
    "                    n_datapoints += len(os.listdir(data_folder))\n",
    "                else:\n",
    "                    n_datapoints+=min(len(os.listdir(data_folder)),max_elements_per_env)\n",
    "            else:\n",
    "                envs.remove(env)\n",
    "        self.n_datapoints = n_datapoints\n",
    "        self.labels = torch.zeros((self.n_datapoints, 1)).float()\n",
    "        self.images = torch.zeros((self.n_datapoints,1,30,30)).float()\n",
    "        n = 0\n",
    "        for env in envs:\n",
    "            print(env)\n",
    "            env_folder = os.path.join(dataset_folder, env)\n",
    "            data_folder = os.path.join(env_folder, \"data\")\n",
    "            dtp_names = os.listdir(data_folder)\n",
    "            dtp_names.sort()\n",
    "            if not max_elements_per_env is None:\n",
    "                dtp_names = dtp_names[0:min(len(dtp_names),max_elements_per_env)]\n",
    "            for dtp_n, dtp_name in enumerate(dtp_names):\n",
    "                print(f\"{dtp_n:04d}\",end=\"\\r\")\n",
    "                dtp_path = os.path.join(data_folder, dtp_name)\n",
    "                dtp = np.load(dtp_path)\n",
    "                self.labels[n, :] = torch.tensor(dtp[\"label\"])\n",
    "                self.images[n,0, :,:] = torch.tensor(dtp[\"image\"])\n",
    "                n+=1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_datapoints\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx, ...]\n",
    "        result = self.labels[idx, ...]\n",
    "        return image.float(), result.float()\n",
    "    def delete(self, idx):\n",
    "        self.images = torch.cat(self.images[0:idx,...],self.images[idx+1,:])\n",
    "        self.labels= torch.cat(self.labels[0:idx,...],self.labels[idx+1,:])\n",
    "\n",
    "dataset = ImageDataset(DATASET_FOLDER,max_elements_per_env=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.2642])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZDklEQVR4nO3df0xV9/3H8ddV8VZbuAwRLneiQ9vqVpVmrjJi6+wkAkuMv/7Qtku0MRodNlPWtaFptW5LWGzimjZO/9lkS6p2JlVTs9lYLJhu4CLVGLONCGETww9XE+5FrFcqn+8f+/auV6EOvJc39/J8JCfx3nO49304SZ893MPB45xzAgBgmI2xHgAAMDoRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGKc9QB36uvrU1tbm1JTU+XxeKzHAQAMknNO3d3dCgQCGjNm4POcERegtrY25ebmWo8BALhPra2tmjJlyoDrR1yAUlNTJUlP6gcapxTjaQAAg/W5evWx/hj57/lA4hagPXv26I033lBHR4fy8/P19ttva/78+ff8ui9+7DZOKRrnIUAAkHD+/w6j9/oYJS4XIbz77rsqLy/Xjh079Mknnyg/P1/FxcW6evVqPN4OAJCA4hKg3bt3a8OGDXr++ef1rW99S/v27dPEiRP129/+Nh5vBwBIQDEP0K1bt9TQ0KCioqL/vsmYMSoqKlJdXd1d24fDYYVCoagFAJD8Yh6gTz/9VLdv31Z2dnbU89nZ2ero6Lhr+8rKSvl8vsjCFXAAMDqY/yJqRUWFgsFgZGltbbUeCQAwDGJ+FVxmZqbGjh2rzs7OqOc7Ozvl9/vv2t7r9crr9cZ6DADACBfzM6Dx48dr3rx5qq6ujjzX19en6upqFRYWxvrtAAAJKi6/B1ReXq61a9fqO9/5jubPn68333xTPT09ev755+PxdgCABBSXAK1evVr//ve/tX37dnV0dOjxxx/XiRMn7rowAQAwenmcc856iC8LhULy+XxapGXcCQEAEtDnrlc1OqZgMKi0tLQBtzO/Cg4AMDoRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMc56AAAjwwdt561HMFEceNx6hFGLMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwUSwEi8USg38cT94gwIAGAi5gF6/fXX5fF4opZZs2bF+m0AAAkuLj+Ce+yxx/Thhx/+903G8ZM+AEC0uJRh3Lhx8vv98XhpAECSiMtnQJcuXVIgEND06dP13HPP6fLlywNuGw6HFQqFohYAQPKLeYAKCgpUVVWlEydOaO/evWppadFTTz2l7u7ufrevrKyUz+eLLLm5ubEeCQAwAnmccy6eb9DV1aVp06Zp9+7dWr9+/V3rw+GwwuFw5HEoFFJubq4WaZnGeVLiORqQMLgMG4nkc9erGh1TMBhUWlragNvF/eqA9PR0Pfroo2pqaup3vdfrldfrjfcYAIARJu6/B3T9+nU1NzcrJycn3m8FAEggMQ/Qiy++qNraWv3zn//UX/7yF61YsUJjx47VM888E+u3AgAksJj/CO7KlSt65plndO3aNU2ePFlPPvmk6uvrNXny5Fi/FQAggcU8QIcOHYr1SwJJZzguKuAiAYx03AsOAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAibj/PSBgNIj3vd2S5b5ug/0+Jct+o3+cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKWCAm2wCnAEBAIwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwb3ggDt80HbeeoSEwPcJ94szIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4FxwQA8WBx61HSAh8n/BlnAEBAEwQIACAiUEH6PTp01q6dKkCgYA8Ho+OHj0atd45p+3btysnJ0cTJkxQUVGRLl26FKt5AQBJYtAB6unpUX5+vvbs2dPv+l27dumtt97Svn37dObMGT344IMqLi7WzZs373tYAEDyGPRFCKWlpSotLe13nXNOb775pl599VUtW7ZMkvT73/9e2dnZOnr0qNasWXN/0wIAkkZMPwNqaWlRR0eHioqKIs/5fD4VFBSorq6u368Jh8MKhUJRCwAg+cU0QB0dHZKk7OzsqOezs7Mj6+5UWVkpn88XWXJzc2M5EgBghDK/Cq6iokLBYDCytLa2Wo8EABgGMQ2Q3++XJHV2dkY939nZGVl3J6/Xq7S0tKgFAJD8YhqgvLw8+f1+VVdXR54LhUI6c+aMCgsLY/lWAIAEN+ir4K5fv66mpqbI45aWFp0/f14ZGRmaOnWqtm7dql/84hd65JFHlJeXp9dee02BQEDLly+P5dwAgAQ36ACdPXtWTz/9dORxeXm5JGnt2rWqqqrSSy+9pJ6eHm3cuFFdXV168skndeLECT3wwAOxmxoAkPA8zjlnPcSXhUIh+Xw+LdIyjfOkWI+DJPBB2/m4v8dovMnmUL6vo/H7NBp97npVo2MKBoNf+bm++VVwAIDRiQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIlB34wUSHbcrwwYHpwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMG94ABIkj5oO289AkYZzoAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBRIUvG+uWhx4PG4vj6SH2dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAvOCSceN/jbLTi3m4YbpwBAQBMDDpAp0+f1tKlSxUIBOTxeHT06NGo9evWrZPH44laSkpKYjUvACBJDDpAPT09ys/P1549ewbcpqSkRO3t7ZHl4MGD9zUkACD5DPozoNLSUpWWln7lNl6vV36/f8hDAQCSX1w+A6qpqVFWVpZmzpypzZs369q1a/F4GwBAAov5VXAlJSVauXKl8vLy1NzcrFdeeUWlpaWqq6vT2LFj79o+HA4rHA5HHodCoViPBAAYgWIeoDVr1kT+PWfOHM2dO1czZsxQTU2NFi9efNf2lZWV2rlzZ6zHAACMcHG/DHv69OnKzMxUU1NTv+srKioUDAYjS2tra7xHAgCMAHH/RdQrV67o2rVrysnJ6Xe91+uV1+uN9xgAgBFm0AG6fv161NlMS0uLzp8/r4yMDGVkZGjnzp1atWqV/H6/mpub9dJLL+nhhx9WcXFxTAcHACS2QQfo7NmzevrppyOPy8vLJUlr167V3r17deHCBf3ud79TV1eXAoGAlixZop///Oec5QAAogw6QIsWLZJzbsD1H3zwwX0NBMQa9zgDRibuBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMDHOegAA9/ZB23nrEYCY4wwIAGBiUAGqrKzUE088odTUVGVlZWn58uVqbGyM2ubmzZsqKyvTpEmT9NBDD2nVqlXq7OyM6dAAgMQ3qADV1taqrKxM9fX1OnnypHp7e7VkyRL19PREttm2bZvef/99HT58WLW1tWpra9PKlStjPjgAILEN6jOgEydORD2uqqpSVlaWGhoatHDhQgWDQf3mN7/RgQMH9P3vf1+StH//fn3zm99UfX29vvvd78ZucgBAQruvz4CCwaAkKSMjQ5LU0NCg3t5eFRUVRbaZNWuWpk6dqrq6un5fIxwOKxQKRS0AgOQ35AD19fVp69atWrBggWbPni1J6ujo0Pjx45Wenh61bXZ2tjo6Ovp9ncrKSvl8vsiSm5s71JEAAAlkyAEqKyvTxYsXdejQofsaoKKiQsFgMLK0trbe1+sBABLDkH4PaMuWLTp+/LhOnz6tKVOmRJ73+/26deuWurq6os6COjs75ff7+30tr9crr9c7lDEAAAlsUGdAzjlt2bJFR44c0alTp5SXlxe1ft68eUpJSVF1dXXkucbGRl2+fFmFhYWxmRgAkBQGdQZUVlamAwcO6NixY0pNTY18ruPz+TRhwgT5fD6tX79e5eXlysjIUFpaml544QUVFhZyBRwAIMqgArR3715J0qJFi6Ke379/v9atWydJ+tWvfqUxY8Zo1apVCofDKi4u1q9//euYDAsASB4e55yzHuLLQqGQfD6fFmmZxnlSrMfBCBTv+6IVBx6P6+sPxVD2eSTuB0aHz12vanRMwWBQaWlpA27HveAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGNLfAwIsDfYeZ4O9j1q87zU3FNzXDcmIMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I0XS40aewMjEGRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGFSAKisr9cQTTyg1NVVZWVlavny5Ghsbo7ZZtGiRPB5P1LJp06aYDg0ASHyDClBtba3KyspUX1+vkydPqre3V0uWLFFPT0/Udhs2bFB7e3tk2bVrV0yHBgAkvnGD2fjEiRNRj6uqqpSVlaWGhgYtXLgw8vzEiRPl9/tjMyEAICnd12dAwWBQkpSRkRH1/DvvvKPMzEzNnj1bFRUVunHjxoCvEQ6HFQqFohYAQPIb1BnQl/X19Wnr1q1asGCBZs+eHXn+2Wef1bRp0xQIBHThwgW9/PLLamxs1Hvvvdfv61RWVmrnzp1DHQMAkKA8zjk3lC/cvHmz/vSnP+njjz/WlClTBtzu1KlTWrx4sZqamjRjxoy71ofDYYXD4cjjUCik3NxcLdIyjfOkDGU0AIChz12vanRMwWBQaWlpA243pDOgLVu26Pjx4zp9+vRXxkeSCgoKJGnAAHm9Xnm93qGMAQBIYIMKkHNOL7zwgo4cOaKamhrl5eXd82vOnz8vScrJyRnSgACA5DSoAJWVlenAgQM6duyYUlNT1dHRIUny+XyaMGGCmpubdeDAAf3gBz/QpEmTdOHCBW3btk0LFy7U3Llz47IDAIDENKjPgDweT7/P79+/X+vWrVNra6t++MMf6uLFi+rp6VFubq5WrFihV1999St/DvhloVBIPp+Pz4AAIEHF5TOge7UqNzdXtbW1g3lJAMAoxb3gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJcdYD3Mk5J0n6XL2SMx4GADBon6tX0n//ez6QEReg7u5uSdLH+qPxJACA+9Hd3S2fzzfgeo+7V6KGWV9fn9ra2pSamiqPxxO1LhQKKTc3V62trUpLSzOacHiNxn2WRud+j8Z9ltjvZNxv55y6u7sVCAQ0ZszAn/SMuDOgMWPGaMqUKV+5TVpaWtIdsHsZjfssjc79Ho37LLHfyearzny+wEUIAAATBAgAYCKhAuT1erVjxw55vV7rUYbNaNxnaXTu92jcZ4n9Hm37/WUj7iIEAMDokFBnQACA5EGAAAAmCBAAwAQBAgCYSJgA7dmzR9/4xjf0wAMPqKCgQH/961+tR4qr119/XR6PJ2qZNWuW9Vgxdfr0aS1dulSBQEAej0dHjx6NWu+c0/bt25WTk6MJEyaoqKhIly5dshk2hu613+vWrbvr2JeUlNgMGyOVlZV64oknlJqaqqysLC1fvlyNjY1R29y8eVNlZWWaNGmSHnroIa1atUqdnZ1GE8fG/7LfixYtuut4b9q0yWji4ZUQAXr33XdVXl6uHTt26JNPPlF+fr6Ki4t19epV69Hi6rHHHlN7e3tk+fjjj61Hiqmenh7l5+drz549/a7ftWuX3nrrLe3bt09nzpzRgw8+qOLiYt28eXOYJ42te+23JJWUlEQd+4MHDw7jhLFXW1ursrIy1dfX6+TJk+rt7dWSJUvU09MT2Wbbtm16//33dfjwYdXW1qqtrU0rV640nPr+/S/7LUkbNmyIOt67du0ymniYuQQwf/58V1ZWFnl8+/ZtFwgEXGVlpeFU8bVjxw6Xn59vPcawkeSOHDkSedzX1+f8fr974403Is91dXU5r9frDh48aDBhfNy53845t3btWrds2TKTeYbL1atXnSRXW1vrnPvPsU1JSXGHDx+ObPP3v//dSXJ1dXVWY8bcnfvtnHPf+9733I9//GO7oQyN+DOgW7duqaGhQUVFRZHnxowZo6KiItXV1RlOFn+XLl1SIBDQ9OnT9dxzz+ny5cvWIw2blpYWdXR0RB13n8+ngoKCpD/uklRTU6OsrCzNnDlTmzdv1rVr16xHiqlgMChJysjIkCQ1NDSot7c36njPmjVLU6dOTarjfed+f+Gdd95RZmamZs+erYqKCt24ccNivGE34m5GeqdPP/1Ut2/fVnZ2dtTz2dnZ+sc//mE0VfwVFBSoqqpKM2fOVHt7u3bu3KmnnnpKFy9eVGpqqvV4cdfR0SFJ/R73L9Ylq5KSEq1cuVJ5eXlqbm7WK6+8otLSUtXV1Wns2LHW4923vr4+bd26VQsWLNDs2bMl/ed4jx8/Xunp6VHbJtPx7m+/JenZZ5/VtGnTFAgEdOHCBb388stqbGzUe++9Zzjt8BjxARqtSktLI/+eO3euCgoKNG3aNP3hD3/Q+vXrDSdDvK1Zsyby7zlz5mju3LmaMWOGampqtHjxYsPJYqOsrEwXL15Mus8072Wg/d64cWPk33PmzFFOTo4WL16s5uZmzZgxY7jHHFYj/kdwmZmZGjt27F1Xw3R2dsrv9xtNNfzS09P16KOPqqmpyXqUYfHFsR3tx12Spk+frszMzKQ49lu2bNHx48f10UcfRf3ZFb/fr1u3bqmrqytq+2Q53gPtd38KCgokKSmO972M+ACNHz9e8+bNU3V1deS5vr4+VVdXq7Cw0HCy4XX9+nU1NzcrJyfHepRhkZeXJ7/fH3XcQ6GQzpw5M6qOuyRduXJF165dS+hj75zTli1bdOTIEZ06dUp5eXlR6+fNm6eUlJSo493Y2KjLly8n9PG+13735/z585KU0Mf7f2Z9FcT/4tChQ87r9bqqqir3t7/9zW3cuNGlp6e7jo4O69Hi5ic/+YmrqalxLS0t7s9//rMrKipymZmZ7urVq9ajxUx3d7c7d+6cO3funJPkdu/e7c6dO+f+9a9/Oeec++Uvf+nS09PdsWPH3IULF9yyZctcXl6e++yzz4wnvz9ftd/d3d3uxRdfdHV1da6lpcV9+OGH7tvf/rZ75JFH3M2bN61HH7LNmzc7n8/nampqXHt7e2S5ceNGZJtNmza5qVOnulOnTrmzZ8+6wsJCV1hYaDj1/bvXfjc1Nbmf/exn7uzZs66lpcUdO3bMTZ8+3S1cuNB48uGREAFyzrm3337bTZ061Y0fP97Nnz/f1dfXW48UV6tXr3Y5OTlu/Pjx7utf/7pbvXq1a2pqsh4rpj766CMn6a5l7dq1zrn/XIr92muvuezsbOf1et3ixYtdY2Oj7dAx8FX7fePGDbdkyRI3efJkl5KS4qZNm+Y2bNiQ8P+z1d/+SnL79++PbPPZZ5+5H/3oR+5rX/uamzhxoluxYoVrb2+3GzoG7rXfly9fdgsXLnQZGRnO6/W6hx9+2P30pz91wWDQdvBhwp9jAACYGPGfAQEAkhMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYOL/ANvWHSkjzgRHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, result = dataset[n]\n",
    "n+=1\n",
    "print(np.rad2deg(result))\n",
    "plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dataset,[0.9,0.1])\n",
    "torch.cuda.empty_cache()\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=5)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=5)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_train(network, train_loader, criterion, optimizer, n_epochs,lr,tensorborad_folder=\"/home/lorenzo/tensor_board\"):\n",
    "    shutil.rmtree(tensorborad_folder) \n",
    "    os.mkdir(tensorborad_folder)\n",
    "    writer = SummaryWriter(log_dir=tensorborad_folder)\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        print(\"\", end=\"\\r\")\n",
    "        print(\"Epoch {} out of {}\".format(\n",
    "            epoch + 1, n_epochs), end=\"\")\n",
    "        for i, data in enumerate(train_loader):\n",
    "            torch.cuda.empty_cache()\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(torch.device(\"cuda\"))\n",
    "            labels = labels.to(torch.device(\"cuda\"))\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            j = i + epoch * train_loader.__len__()\n",
    "            writer.add_scalar(f\"Loss/train/lr_{lr}\",loss,j)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(\"/home/lorenzo/models/gallery_detection/procedural_datasets/dataset_03/gallery_detector_v3-_r10_lr002_3.torch\", \"rb\") as f:\n",
    "        network.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100000\n",
      "0.065000\n",
      "0.042250\n",
      "0.027463\n",
      "0.017851\n",
      "0.011603\n",
      "0.007542\n",
      "0.004902\n",
      "0.003186\n",
      "0.002071\n",
      "0.001346\n",
      "0.000875\n",
      "0.000569\n",
      "0.000370\n",
      "0.000240\n",
      "0.000156\n",
      "0.000102\n",
      "0.000066\n",
      "0.000043\n",
      "0.000028\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.1*0.65**n for n in range(20)]\n",
    "for i in lrs:\n",
    "    print(f\"{i:05f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.06, 0.036, 0.021599999999999998, 0.01296, 0.007775999999999998, 0.004665599999999999, 0.0027993599999999994, 0.0016796159999999994, 0.0010077695999999997, 0.0006046617599999998, 0.0003627970559999999, 0.00021767823359999992, 0.00013060694015999994, 7.836416409599996e-05, 4.701849845759997e-05, 2.8211099074559986e-05, 1.692665944473599e-05, 1.0155995666841594e-05, 6.093597400104956e-06]\n",
      "Epoch 1 out of 1/home/lorenzo/models/gallery_detection/procedural_datasets/fast_tunnel_traversal/YawEstimator-_bs128_ne1_lr0_100000.torch\n",
      "Epoch 1 out of 1"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m      6\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\n\u001b[1;32m      7\u001b[0m     network\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m      8\u001b[0m     lr\u001b[39m=\u001b[39mlr,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m loss_hist \u001b[39m=\u001b[39m basic_train(\n\u001b[1;32m     11\u001b[0m     network, train_dataloader, criterion, optimizer, n_epochs, lr\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m lr_str \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlr\u001b[39m:\u001b[39;00m\u001b[39m04f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m save_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(SAVE_FOLDER,MODEL\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m+\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m-_bs\u001b[39m\u001b[39m{\u001b[39;00mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m_ne\u001b[39m\u001b[39m{\u001b[39;00mn_epochs\u001b[39m}\u001b[39;00m\u001b[39m_lr\u001b[39m\u001b[39m{\u001b[39;00mlr_str\u001b[39m}\u001b[39;00m\u001b[39m.torch\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m, in \u001b[0;36mbasic_train\u001b[0;34m(network, train_loader, criterion, optimizer, n_epochs, lr, tensorborad_folder)\u001b[0m\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m j \u001b[39m=\u001b[39m i \u001b[39m+\u001b[39m epoch \u001b[39m*\u001b[39m train_loader\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/train_nn/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/train_nn/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "for lr in lrs:\n",
    "    network = MODEL().to(cuda).float()\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        network.parameters(),\n",
    "        lr=lr,\n",
    "    )\n",
    "    loss_hist = basic_train(\n",
    "        network, train_dataloader, criterion, optimizer, n_epochs, lr\n",
    "    )\n",
    "    lr_str = f\"{lr:04f}\".replace(\".\", \"_\")\n",
    "    save_path = os.path.join(SAVE_FOLDER,MODEL.__name__+f\"-_bs{batch_size}_ne{n_epochs}_lr{lr_str}.torch\")\n",
    "    print(save_path)\n",
    "    network.to(\"cpu\")\n",
    "    torch.save(network.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/models/gallery_detection/procedural_datasets/dataset_03/gallery_detector_v3-_r10_lr002_5.torch\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/lorenzo/models/gallery_detection/procedural_datasets/dataset_03/gallery_detector_v3-_r10_lr002_5.torch\"\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
